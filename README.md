# Mirror-BERT

Code repo for the EMNLP 2021 paper: [*Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders*](https://arxiv.org/pdf/2104.08027.pdf).

## Hugginface pretrained models

[[mirror-bert-base-uncased-sentence]](https://huggingface.co/cambridgeltl/mirror-bert-base-uncased-sentence)<br>
[[mirror-roberta-base-sentence]](https://huggingface.co/cambridgeltl/mirror-roberta-base-sentence)<br>
[[mirror-bert-base-uncased-sentence-drophead]](https://huggingface.co/cambridgeltl/mirror-bert-base-uncased-sentence-drophead)<br>
[[mirror-roberta-base-sentence-drophead]](https://huggingface.co/cambridgeltl/mirror-roberta-base-sentence-drophead)<br>

Codes and more model weights coming in a few days!

## Citation
```bibtex
@inproceedings{
	liu2021fast,
  title={Fast, Effective and Self-Supervised: Transforming Masked LanguageModels into Universal Lexical and Sentence Encoders},
  author={Liu, Fangyu and Vuli{\'c}, Ivan and Korhonen, Anna and Collier, Nigel},
  booktitle={EMNLP 2021},
  year={2021}
}
```
